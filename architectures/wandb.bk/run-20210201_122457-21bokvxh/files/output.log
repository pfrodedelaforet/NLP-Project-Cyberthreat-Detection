2021-02-01 12:25:00.067834: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
      type: DT_INT32
    }
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 1
        }
        dim {
          size: 512
        }
      }
      shape {
        dim {
          size: 1
        }
        dim {
          size: 512
        }
      }
    }
  }
}

2021-02-01 12:25:00.125144: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-02-01 12:25:00.143395: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz
{'attention_mask': <tf.Tensor 'while/strided_slice_1:0' shape=(8, 1, 512) dtype=int32>, 'global_attention_mask': None, 'token_type_ids': None, 'position_ids': None, 'inputs_embeds': None, 'output_attentions': False, 'output_hidden_states': False, 'return_dict': True, 'labels': <tf.Tensor 'while/strided_slice_2:0' shape=(8,) dtype=int32>, 'training': True, 'kwargs_call': {}, 'input_ids': <tf.Tensor 'while/strided_slice:0' shape=(8, 1, 512) dtype=int32>}
Traceback (most recent call last):
  File "prosenet.py", line 105, in <module>
    trainer.train()
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/transformers/trainer_tf.py", line 549, in train
    self.distributed_training_steps(batch)
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 726, in _initialize
    *args, **kwds))
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 3206, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 3887, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File "/home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/transformers/trainer_tf.py:671 distributed_training_steps  *
        self.args.strategy.run(self.apply_gradients, inputs)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/transformers/trainer_tf.py:643 apply_gradients  *
        self.training_step(reduced_features, reduced_labels, nb_instances_in_global_batch)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/transformers/trainer_tf.py:616 training_step  *
        per_example_loss, _ = self.run_model(features, labels, True)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/transformers/trainer_tf.py:718 run_model  *
        outputs = self.model(features, labels=labels, training=training)[:2]
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/transformers/models/longformer/modeling_tf_longformer.py:2378 call  *
        inputs["global_attention_mask"] = tf.tensor_scatter_nd_update(
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **
        return target(*args, **kwargs)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5512 tensor_scatter_nd_update
        tensor=tensor, indices=indices, updates=updates, name=name)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:11247 tensor_scatter_update
        updates=updates, name=name)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal
        compute_device)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal
        op_def=op_def)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2016 __init__
        control_input_ops, op_def)
    /home/pfrod/anaconda3/envs/env_minus/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op
        raise ValueError(str(e))

    ValueError: Dimensions [2,3) of input[shape=[8,1,512]] = [512] must match dimensions [1,1) of updates[shape=[8]] = []: Shapes must be equal rank, but are 1 and 0 for '{{node while/tf_longformer_for_sequence_classification/TensorScatterUpdate}} = TensorScatterUpdate[T=DT_INT32, Tindices=DT_INT32](while/tf_longformer_for_sequence_classification/zeros_like, while/tf_longformer_for_sequence_classification/TensorScatterUpdate/indices, while/tf_longformer_for_sequence_classification/TensorScatterUpdate/updates)' with input shapes: [8,1,512], [8,2], [8].

